{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85aafe3-c3ea-41bc-9953-2b081fcabc41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.52.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeabf30-442d-40bd-bda6-54ae07a02221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gigbot: Hello! I'm Gigbot, here to help you create an exciting challenge on Kinetik. To get started, could you please provide me with a brief summary of the event you have in mind?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  hi gigbot. I want to create a gig where competitors develop an in=vitro matlab program that runs on printers. This will present one of the biggest. advances in programming as we will be able to print out fortran code and have it automaticvally converted into matlab. The prize will be 5 quadrillion dollars for a senior programmer, while a junior programmer can earn the mayorship for ooty, worth about 5 septillion dollars. The date of submission due date is january second 2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Let's set up your challenge on Kinetik platform. \n",
      "\n",
      "Event Name: In-Vitro MATLAB Program Challenge\n",
      "Deadline date and time in PST: January 2, 2030, 11:59 PM PST\n",
      "Short description: Develop an innovative in-vitro MATLAB program for printers.\n",
      "Long description: Join us in revolutionizing programming by creating a MATLAB program that can print out Fortran code and automatically convert it. This challenge presents a significant advance in coding. Show off your skills and compete for the substantial cash prize!\n",
      "Total cash prize in USD: $5,000,000,000,000 for senior programmers, Mayorship for Ooty (~$5,000,000,000,000,000) for junior programmers\n",
      "Required skills: MATLAB, Programming, Printer Technology, Fortran\n",
      "Other prizes/incentives: Mayorship for Ooty\n",
      "\n",
      "DONE\n",
      "Gigbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "# Function to get response from OpenAI's GPT-3.5-turbo model\n",
    "def get_gpt_response(messages):\n",
    "    response = openai.chat.completions.create(  # Updated method name for v1.0.0+\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "initial_context = open(\"initial_context.txt\", \"r\").read()\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = [\n",
    "    {\"role\": \"system\", \"content\": initial_context}\n",
    "]\n",
    "\n",
    "solution_to_parse = None\n",
    "\n",
    "while True:\n",
    "    # Get response from GPT-3.5-turbo\n",
    "    assistant_response = get_gpt_response(conversation_history)\n",
    "\n",
    "    if \"DONE\" in assistant_response:\n",
    "        print(assistant_response)\n",
    "        print(\"Gigbot: Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    # Print the response and add it to the conversation history\n",
    "    print(f\"Gigbot: {assistant_response}\")\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    # End the conversation if the user types 'exit'\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Gigbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Append the user's message to the conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd7975-cba8-41fa-ab1c-597553d22dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_str = \"\"\n",
    "\n",
    "for i in conversation_history:\n",
    "    if i[\"role\"] == \"user\":\n",
    "        conversation_str += \"User: \" + i[\"content\"] + \"\\n\"\n",
    "    elif i[\"role\"] == \"assistant\":\n",
    "        conversation_str += \"Assistant: \" + i[\"content\"] + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0365c1-f120-4fbf-8b44-d623be72dd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"event_name\": \"In-Vitro Matlab Program Challenge\",\n",
      "  \"deadline\": \"January 2, 2030\",\n",
      "  \"short_desc\": \"Develop an innovative in-vitro Matlab program for printers.\",\n",
      "  \"long_desc\": \"Participants will create a program that automatically converts Fortran code into Matlab for printing. The challenge presents a significant advancement in programming. Cash prizes include 5 quadrillion dollars for senior programmers and the mayorship of Ooty, valued at 5 septillion dollars, for junior programmers.\",\n",
      "  \"cash_prize\": 5000000000000000,\n",
      "  \"required_skills\": \"Matlab, Programming, Fortran\",\n",
      "  \"other_prizes\": \"Mayorship of Ooty\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Hi ChatGPT, please help me populate an empty JSON dictionary based on our conversation.\n",
    "Use inferred values from the context we've discussed. Below is the empty JSON structure for reference:\n",
    "\n",
    "{}\n",
    "\n",
    "You can fill in keys and values as you understand from our dialogue, adding relevant fields and values as needed. Make sure the following keys are filled out\n",
    "\n",
    "event_name: [some string]\n",
    "deadline: [date and time]\n",
    "short_desc: [some string less than 50 words]\n",
    "long_desc : [some longer string]\n",
    "cash_prize: [some number]\n",
    "required_skills: [a bunch of strings separated by commas]\n",
    "other_prizes: [a comma seperated list of strings]\n",
    "\n",
    "Here is the conversation:\n",
    "\"\"\" + conversation_str\n",
    "\n",
    "# Make the API call to ChatGPT\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Extract and print the response\n",
    "filled_json = response.choices[0].message.content\n",
    "print(filled_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
